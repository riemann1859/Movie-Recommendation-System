{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, load 4 datasets\n",
    "#then combine ratings and ratings_test\n",
    "\n",
    "add1=\"C:/Users/YUNUS/Downloads/ml2_project/data/u.base\"\n",
    "\n",
    "add2=\"C:/Users/YUNUS/Downloads/ml2_project/data/u.test\"\n",
    "\n",
    "ratings=pd.read_csv(add1,header=None,names=[\"userid\",\"filmid\",\"rating\",\"timestamp\"], sep=\"\\t\")\n",
    "ratings_test=pd.read_csv(add2,header=None,names=[\"userid\",\"filmid\",\"rating\",\"timestamp\"], sep=\"\\t\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filmid  1     2     3     4     5     6     7     8     9     10    ...  1673  \\\n",
      "userid                                                              ...         \n",
      "1        5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   NaN   \n",
      "2        4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   NaN   \n",
      "3        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "4        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "5        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "6        4.0   NaN   NaN   NaN   NaN   NaN   2.0   4.0   4.0   NaN  ...   NaN   \n",
      "7        NaN   NaN   NaN   5.0   NaN   NaN   5.0   5.0   5.0   4.0  ...   NaN   \n",
      "8        NaN   NaN   NaN   NaN   NaN   NaN   3.0   NaN   NaN   NaN  ...   NaN   \n",
      "9        NaN   NaN   NaN   NaN   NaN   NaN   4.0   NaN   NaN   NaN  ...   NaN   \n",
      "10       4.0   NaN   NaN   4.0   NaN   NaN   NaN   NaN   4.0   NaN  ...   NaN   \n",
      "11       NaN   NaN   NaN   NaN   NaN   NaN   NaN   4.0   5.0   NaN  ...   NaN   \n",
      "12       NaN   NaN   NaN   5.0   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "13       3.0   3.0   NaN   5.0   1.0   NaN   2.0   4.0   3.0   NaN  ...   NaN   \n",
      "14       NaN   NaN   NaN   NaN   NaN   NaN   5.0   NaN   4.0   NaN  ...   NaN   \n",
      "15       1.0   NaN   NaN   NaN   NaN   NaN   1.0   NaN   4.0   NaN  ...   NaN   \n",
      "16       5.0   NaN   NaN   5.0   NaN   NaN   5.0   NaN   5.0   NaN  ...   NaN   \n",
      "17       NaN   NaN   NaN   NaN   NaN   NaN   4.0   NaN   NaN   NaN  ...   NaN   \n",
      "18       5.0   NaN   NaN   3.0   NaN   5.0   NaN   5.0   5.0   NaN  ...   NaN   \n",
      "19       NaN   NaN   NaN   NaN   NaN   NaN   NaN   5.0   NaN   NaN  ...   NaN   \n",
      "20       3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "21       5.0   NaN   NaN   NaN   2.0   NaN   5.0   NaN   5.0   NaN  ...   NaN   \n",
      "22       NaN   2.0   NaN   5.0   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "23       5.0   NaN   NaN   NaN   NaN   NaN   4.0   4.0   NaN   NaN  ...   NaN   \n",
      "24       NaN   NaN   NaN   NaN   NaN   NaN   4.0   5.0   5.0   NaN  ...   NaN   \n",
      "25       5.0   NaN   NaN   NaN   NaN   NaN   4.0   4.0   NaN   NaN  ...   NaN   \n",
      "26       3.0   NaN   NaN   NaN   NaN   NaN   3.0   NaN   4.0   NaN  ...   NaN   \n",
      "27       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   4.0   NaN  ...   NaN   \n",
      "28       NaN   NaN   NaN   NaN   3.0   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "29       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "30       NaN   3.0   NaN   NaN   NaN   NaN   4.0   NaN   NaN   NaN  ...   NaN   \n",
      "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "914      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "915      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "916      4.0   3.0   3.0   4.0   3.0   NaN   4.0   NaN   5.0   NaN  ...   NaN   \n",
      "917      3.0   NaN   1.0   NaN   NaN   NaN   NaN   NaN   5.0   NaN  ...   NaN   \n",
      "918      3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "919      4.0   NaN   NaN   1.0   4.0   NaN   3.0   NaN   5.0   NaN  ...   NaN   \n",
      "920      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "921      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "922      5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "923      3.0   NaN   4.0   NaN   NaN   NaN   NaN   NaN   4.0   NaN  ...   NaN   \n",
      "924      5.0   3.0   NaN   NaN   NaN   NaN   4.0   NaN   4.0   NaN  ...   NaN   \n",
      "925      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "926      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "927      5.0   NaN   NaN   NaN   NaN   NaN   NaN   4.0   NaN   NaN  ...   NaN   \n",
      "928      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   5.0   NaN  ...   NaN   \n",
      "929      3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "930      3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "931      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "932      4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   5.0   NaN  ...   NaN   \n",
      "933      3.0   NaN   NaN   3.0   NaN   NaN   4.0   NaN   3.0   NaN  ...   NaN   \n",
      "934      2.0   4.0   NaN   5.0   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "935      3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   1.0   NaN  ...   NaN   \n",
      "936      4.0   NaN   4.0   NaN   NaN   5.0   4.0   NaN   4.0   NaN  ...   NaN   \n",
      "937      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "938      4.0   NaN   NaN   NaN   NaN   NaN   4.0   NaN   3.0   NaN  ...   NaN   \n",
      "939      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   5.0   NaN  ...   NaN   \n",
      "940      NaN   NaN   NaN   2.0   NaN   NaN   4.0   5.0   3.0   NaN  ...   NaN   \n",
      "941      5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "942      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "943      NaN   5.0   NaN   NaN   NaN   NaN   NaN   NaN   3.0   NaN  ...   NaN   \n",
      "\n",
      "filmid  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
      "userid                                                        \n",
      "1        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "4        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "5        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "6        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "7        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "8        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "9        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "10       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "11       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "12       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "13       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "14       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "15       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "16       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "17       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "18       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "19       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "20       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "21       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "22       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "23       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "24       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "25       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "26       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "27       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "28       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "29       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "30       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "...      ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "914      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "915      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "916      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   3.0  \n",
      "917      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "918      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "919      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "920      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "921      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "922      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "923      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "924      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "925      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "926      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "927      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "928      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "929      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "930      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "931      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "932      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "933      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "934      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "935      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "936      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "937      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "938      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "939      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "940      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "941      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "942      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "943      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[943 rows x 1680 columns]\n"
     ]
    }
   ],
   "source": [
    "# convert combined_ratings into pivot table\n",
    "\n",
    "utility=pd.pivot_table(ratings, values='rating',index='userid',columns='filmid',fill_value=np.nan)\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "print(utility)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 1.088130552276007\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "\n",
    "when predicting a rating for a film given by a user, consider all users rating this film,\n",
    "and then take an average of all those ratings\n",
    "\n",
    "\"\"\"\"\"\n",
    "means=utility.mean(axis=1).values\n",
    "pred_=[]\n",
    "for rownumber, row in ratings_test.iterrows():\n",
    "    try:\n",
    "        pred_.append(avgs[row['filmid']])\n",
    "    except:\n",
    "        \n",
    "        pred_.append(means[row['userid']-1])\n",
    "    \n",
    "print(\"Mean squared error:\", mean_squared_error(pred_,ratings_test.rating))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.9637031816291289\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "\n",
    "Consider the ratings x_1,...,x_n given by an arbitrarily chosen user. Normalize these, that is,\n",
    "subtract the average (x_1+...+x_n)/n from the ratings. This tells us whether a user rates the movie above the average\n",
    "movie he has rated or below that average. Normalize the ratings of each user. The remaining is the same as the above.\n",
    "\n",
    "\"\"\"\"\"\n",
    "\n",
    "\n",
    "user_avgs=ratings.groupby('userid')['rating'].mean()\n",
    "ratings['diff']=ratings[['userid','rating']].apply(lambda x:x[1]-user_avgs[x[0]],axis=1)\n",
    "contributions=ratings.groupby('filmid')['diff'].mean()\n",
    "\n",
    "pred_=[]\n",
    "for rownumber, row in ratings_test.iterrows():\n",
    "    try:\n",
    "        pred_.append(means[row['userid']-1]+contributions[row['filmid']])\n",
    "    except:\n",
    "        \n",
    "        pred_.append(means[row['userid']-1])\n",
    "    \n",
    "print(\"Mean squared error:\", mean_squared_error(pred_,ratings_test.rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.9874174178050048\n",
      "--- 1253.2335002422333 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Instead of taking average over all users rating a film in question, we only consider \n",
    "the most similar users to a user we want to predict. We  measure\n",
    "similarity of users  via the Pearson Correlation formula.\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Finds the Pearson Correlation Similarity Measure between two users\n",
    "#This Pearson correlation and Pandas' Pearson correlation are a bit different\n",
    "\n",
    "def pcs(x, rowx, y,rowy):\n",
    "    \n",
    "    corr=0\n",
    "    var_x=0\n",
    "    var_y=0\n",
    "    for a,b in zip(x,y):\n",
    "        if a>0 and b>0:\n",
    "            corr+=((a-means[rowx])*(b-means[rowy]))\n",
    "            var_x+=(a-means[rowx])**2\n",
    "            var_y+=(b-means[rowy])**2\n",
    "    if corr==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return corr/np.sqrt(var_x*var_y)\n",
    "                \n",
    "\n",
    "# Guesses the ratings that user with id, user_id, might give to item with id, i_id.\n",
    "# We will consider the top_n similar users to do this. \n",
    "def guess(user_id, i_id, top_n):\n",
    "    \n",
    "    list_of_corr=list()\n",
    "    for row_number in range(utility.shape[0]):\n",
    "        if row_number!=user_id-1 and  utility.iloc[row_number,i_id-1]>0:\n",
    "            list_of_corr.append((row_number,pcs(utility.iloc[user_id-1,:],user_id-1,utility.iloc[row_number,:],row_number)))\n",
    "    list_of_corr.sort(key=lambda x:x[1],reverse=True)\n",
    "    \n",
    "    user_guess=means[user_id-1]\n",
    "    \n",
    "    for row_number, corr in list_of_corr[:top_n]:\n",
    "        user_guess+=((utility.iloc[row_number,i_id-1]-means[row_number])/min(len(list_of_corr),top_n))\n",
    "    \n",
    "    \n",
    "    return user_guess\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n = 10 # Assume top_n users\n",
    "import time\n",
    "start_time = time.time()\n",
    "    \n",
    "pred_=[]\n",
    "for rownumber, row in ratings_test.iterrows():\n",
    "    pred_.append(guess(row['userid'],row['filmid'],10))\n",
    "    \n",
    "print(\"Mean squared error:\", mean_squared_error(pred_,ratings_test.rating))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea averaging over the most similar users seems promising, but does not improve the result coming from the second case.\n",
    "Why? It is difficult to detect the similarity between items and users because we have little information about user-item pairs in this sparse utility matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
